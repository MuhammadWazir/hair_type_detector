{"cells":[{"cell_type":"markdown","metadata":{"id":"bu5O4ooIiZ3X"},"source":["Necessary imports"]},{"cell_type":"code","execution_count":45,"metadata":{"executionInfo":{"elapsed":395,"status":"ok","timestamp":1729242015547,"user":{"displayName":"Muhammad El Wazir","userId":"00752065405578931370"},"user_tz":-180},"id":"cq2leV-oibmi"},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","import os"]},{"cell_type":"code","execution_count":46,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28694,"status":"ok","timestamp":1729242045411,"user":{"displayName":"Muhammad El Wazir","userId":"00752065405578931370"},"user_tz":-180},"id":"7hgYvmr7Yzpx","outputId":"7ad1f4d0-e0ba-454a-80c1-5bdbac2e362d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Directory: Straight\n","Directory: Wavy\n","Directory: curly\n","Directory: dreadlocks\n","Directory: kinky\n","Loaded 1992 images with 1992 labels.\n"]}],"source":["import os\n","from PIL import Image\n","import numpy as np\n","\n","parent_directory = \"/content/drive/MyDrive/hair_type_detector/data\"\n","X = []\n","y = []\n","\n","# Define class labels (you can assign based on directory names)\n","class_labels = {'Straight': 0, 'Wavy': 1, 'curly': 2, 'dreadlocks': 3, 'kinky': 4}\n","\n","for dir_name in os.listdir(parent_directory):\n","    dir_path = os.path.join(parent_directory, dir_name)\n","\n","    if os.path.isdir(dir_path) and dir_name in class_labels:\n","        print(f\"Directory: {dir_name}\")\n","\n","        for file_name in os.listdir(dir_path):\n","            file_path = os.path.join(dir_path, file_name)\n","\n","            if os.path.isfile(file_path):\n","                try:\n","                    img = Image.open(file_path)\n","\n","                    # Convert the image to grayscale (L mode)\n","                    img = img.convert('L')\n","\n","                    # Resize the image to a standard size (e.g., 150x150) to make it uniform\n","                    img = img.resize((150, 150))\n","\n","                    img_array = np.array(img)\n","                    X.append(img_array)\n","                    y.append(class_labels[dir_name])\n","                except Exception as e:\n","                    print(f\"Error loading image {file_name}: {e}\")\n","\n","# Convert lists to numpy arrays\n","X = np.array(X)\n","y = np.array(y)\n","\n","print(f\"Loaded {len(X)} images with {len(y)} labels.\")\n"]},{"cell_type":"markdown","metadata":{"id":"PpjoVomFjbBb"},"source":["Perform data augmentation"]},{"cell_type":"code","execution_count":47,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":619,"status":"ok","timestamp":1729242048062,"user":{"displayName":"Muhammad El Wazir","userId":"00752065405578931370"},"user_tz":-180},"id":"H9fS6xUsbk1s","outputId":"7ac9f16e-724d-4ec0-f1d4-f6d624a8a0c8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Training set size: 1593 images\n","Test set size: 399 images\n"]}],"source":["from sklearn.model_selection import train_test_split\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","X_train = np.expand_dims(X_train, axis=-1)\n","X_test = np.expand_dims(X_test, axis=-1)\n","print(f\"Training set size: {len(X_train)} images\")\n","print(f\"Test set size: {len(X_test)} images\")\n","\n","# 2. Data Augmentation for Training Set\n","train_datagen = ImageDataGenerator(\n","    rescale=1. / 255,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    brightness_range=(0.3, 1.0),\n","    horizontal_flip=True,\n","    vertical_flip=True,\n","    fill_mode='nearest',\n","    validation_split=0.2\n",")\n","test_datagen = ImageDataGenerator(rescale=1./255)\n","train_generator = train_datagen.flow(\n","    X_train,\n","    y_train,\n","    batch_size=32,\n","    subset='training'\n",")\n","\n","# Create the generator for the validation set (from training data)\n","validation_generator = train_datagen.flow(\n","    X_train,\n","    y_train,\n","    batch_size=32,\n","    subset='validation'\n",")\n","\n","# For the actual test set (untouched during training), you can use test_datagen\n","test_generator = test_datagen.flow(\n","    X_test,\n","    y_test,\n","    batch_size=32\n",")"]},{"cell_type":"code","execution_count":48,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"7dqx_tWEjdvA","executionInfo":{"status":"ok","timestamp":1729242731504,"user_tz":-180,"elapsed":679083,"user":{"displayName":"Muhammad El Wazir","userId":"00752065405578931370"}},"outputId":"9162f8a0-c601-4049-958e-87e1678c73c7"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 208ms/step - accuracy: 0.2691 - loss: 1.6080 - val_accuracy: 0.2453 - val_loss: 1.5777\n","Epoch 2/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 80ms/step - accuracy: 0.2131 - loss: 1.5978 - val_accuracy: 0.2484 - val_loss: 1.5806\n","Epoch 3/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - accuracy: 0.2623 - loss: 1.5677 - val_accuracy: 0.2579 - val_loss: 1.5778\n","Epoch 4/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 109ms/step - accuracy: 0.2334 - loss: 1.5799 - val_accuracy: 0.2484 - val_loss: 1.5774\n","Epoch 5/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 81ms/step - accuracy: 0.2680 - loss: 1.5755 - val_accuracy: 0.2484 - val_loss: 1.5797\n","Epoch 6/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 78ms/step - accuracy: 0.2428 - loss: 1.5783 - val_accuracy: 0.2484 - val_loss: 1.5809\n","Epoch 7/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 114ms/step - accuracy: 0.2474 - loss: 1.5751 - val_accuracy: 0.2484 - val_loss: 1.5817\n","Epoch 8/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 81ms/step - accuracy: 0.2702 - loss: 1.5693 - val_accuracy: 0.2547 - val_loss: 1.5758\n","Epoch 9/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 80ms/step - accuracy: 0.2637 - loss: 1.5647 - val_accuracy: 0.2704 - val_loss: 1.5735\n","Epoch 10/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 89ms/step - accuracy: 0.2491 - loss: 1.5655 - val_accuracy: 0.2830 - val_loss: 1.5609\n","Epoch 11/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 108ms/step - accuracy: 0.3145 - loss: 1.5349 - val_accuracy: 0.3019 - val_loss: 1.5462\n","Epoch 12/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 80ms/step - accuracy: 0.3034 - loss: 1.5427 - val_accuracy: 0.3302 - val_loss: 1.5213\n","Epoch 13/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - accuracy: 0.3219 - loss: 1.5226 - val_accuracy: 0.2421 - val_loss: 1.5443\n","Epoch 14/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 120ms/step - accuracy: 0.3397 - loss: 1.5202 - val_accuracy: 0.2516 - val_loss: 1.5495\n","Epoch 15/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 81ms/step - accuracy: 0.3314 - loss: 1.4892 - val_accuracy: 0.3522 - val_loss: 1.4952\n","Epoch 16/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 117ms/step - accuracy: 0.3948 - loss: 1.4517 - val_accuracy: 0.3491 - val_loss: 1.5279\n","Epoch 17/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 82ms/step - accuracy: 0.3675 - loss: 1.5103 - val_accuracy: 0.3553 - val_loss: 1.4707\n","Epoch 18/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - accuracy: 0.3604 - loss: 1.4833 - val_accuracy: 0.2767 - val_loss: 1.5110\n","Epoch 19/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 0.3579 - loss: 1.4545 - val_accuracy: 0.3805 - val_loss: 1.4824\n","Epoch 20/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - accuracy: 0.3895 - loss: 1.4289 - val_accuracy: 0.4088 - val_loss: 1.4433\n","Epoch 21/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 81ms/step - accuracy: 0.3757 - loss: 1.4407 - val_accuracy: 0.3931 - val_loss: 1.4191\n","Epoch 22/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 103ms/step - accuracy: 0.4086 - loss: 1.4634 - val_accuracy: 0.3836 - val_loss: 1.4427\n","Epoch 23/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 82ms/step - accuracy: 0.3839 - loss: 1.4097 - val_accuracy: 0.4371 - val_loss: 1.4246\n","Epoch 24/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 81ms/step - accuracy: 0.3823 - loss: 1.4235 - val_accuracy: 0.3868 - val_loss: 1.4367\n","Epoch 25/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 109ms/step - accuracy: 0.4024 - loss: 1.4097 - val_accuracy: 0.3396 - val_loss: 1.4878\n","Epoch 26/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.3937 - loss: 1.4377 - val_accuracy: 0.4151 - val_loss: 1.4100\n","Epoch 27/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 78ms/step - accuracy: 0.4160 - loss: 1.4170 - val_accuracy: 0.4119 - val_loss: 1.4057\n","Epoch 28/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - accuracy: 0.4161 - loss: 1.3808 - val_accuracy: 0.3616 - val_loss: 1.4731\n","Epoch 29/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 81ms/step - accuracy: 0.4254 - loss: 1.3948 - val_accuracy: 0.3931 - val_loss: 1.4492\n","Epoch 30/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 81ms/step - accuracy: 0.3789 - loss: 1.4109 - val_accuracy: 0.4088 - val_loss: 1.4126\n","Epoch 31/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 107ms/step - accuracy: 0.4100 - loss: 1.3880 - val_accuracy: 0.4119 - val_loss: 1.4091\n","Epoch 32/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 81ms/step - accuracy: 0.4315 - loss: 1.3855 - val_accuracy: 0.3868 - val_loss: 1.4254\n","Epoch 33/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 78ms/step - accuracy: 0.4050 - loss: 1.3793 - val_accuracy: 0.3868 - val_loss: 1.4112\n","Epoch 34/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 122ms/step - accuracy: 0.4132 - loss: 1.3857 - val_accuracy: 0.4151 - val_loss: 1.3848\n","Epoch 35/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 82ms/step - accuracy: 0.4297 - loss: 1.3547 - val_accuracy: 0.3868 - val_loss: 1.4254\n","Epoch 36/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 78ms/step - accuracy: 0.3854 - loss: 1.3955 - val_accuracy: 0.4057 - val_loss: 1.4262\n","Epoch 37/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - accuracy: 0.4042 - loss: 1.3729 - val_accuracy: 0.3868 - val_loss: 1.4209\n","Epoch 38/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - accuracy: 0.4240 - loss: 1.3519 - val_accuracy: 0.4340 - val_loss: 1.3480\n","Epoch 39/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 78ms/step - accuracy: 0.4359 - loss: 1.3122 - val_accuracy: 0.3428 - val_loss: 1.5186\n","Epoch 40/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 89ms/step - accuracy: 0.3849 - loss: 1.4131 - val_accuracy: 0.3836 - val_loss: 1.4431\n","Epoch 41/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 100ms/step - accuracy: 0.4450 - loss: 1.2935 - val_accuracy: 0.3805 - val_loss: 1.4241\n","Epoch 42/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - accuracy: 0.4490 - loss: 1.2923 - val_accuracy: 0.4214 - val_loss: 1.3468\n","Epoch 43/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - accuracy: 0.4379 - loss: 1.2782 - val_accuracy: 0.3994 - val_loss: 1.4241\n","Epoch 44/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 117ms/step - accuracy: 0.3814 - loss: 1.3338 - val_accuracy: 0.4245 - val_loss: 1.3705\n","Epoch 45/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 82ms/step - accuracy: 0.4407 - loss: 1.2749 - val_accuracy: 0.4088 - val_loss: 1.3337\n","Epoch 46/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 102ms/step - accuracy: 0.4499 - loss: 1.2833 - val_accuracy: 0.4057 - val_loss: 1.3574\n","Epoch 47/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - accuracy: 0.4401 - loss: 1.2504 - val_accuracy: 0.3962 - val_loss: 1.3326\n","Epoch 48/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 98ms/step - accuracy: 0.4543 - loss: 1.2558 - val_accuracy: 0.4119 - val_loss: 1.3538\n","Epoch 49/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - accuracy: 0.4376 - loss: 1.2736 - val_accuracy: 0.4434 - val_loss: 1.3268\n","Epoch 50/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - accuracy: 0.4612 - loss: 1.2314 - val_accuracy: 0.3679 - val_loss: 1.3943\n","Epoch 51/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 104ms/step - accuracy: 0.4479 - loss: 1.3035 - val_accuracy: 0.4151 - val_loss: 1.3236\n","Epoch 52/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.4376 - loss: 1.2869 - val_accuracy: 0.3962 - val_loss: 1.4343\n","Epoch 53/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 80ms/step - accuracy: 0.4460 - loss: 1.3533 - val_accuracy: 0.4088 - val_loss: 1.3702\n","Epoch 54/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 103ms/step - accuracy: 0.4308 - loss: 1.2941 - val_accuracy: 0.4151 - val_loss: 1.3278\n","Epoch 55/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 87ms/step - accuracy: 0.4285 - loss: 1.3096 - val_accuracy: 0.4371 - val_loss: 1.3468\n","Epoch 56/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - accuracy: 0.4545 - loss: 1.3148 - val_accuracy: 0.4119 - val_loss: 1.4132\n","Epoch 57/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 101ms/step - accuracy: 0.4543 - loss: 1.2620 - val_accuracy: 0.4057 - val_loss: 1.3217\n","Epoch 58/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 86ms/step - accuracy: 0.4950 - loss: 1.2062 - val_accuracy: 0.4119 - val_loss: 1.3014\n","Epoch 59/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 80ms/step - accuracy: 0.4533 - loss: 1.2464 - val_accuracy: 0.4843 - val_loss: 1.3125\n","Epoch 60/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 0.4920 - loss: 1.2307 - val_accuracy: 0.4214 - val_loss: 1.3206\n","Epoch 61/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 80ms/step - accuracy: 0.5020 - loss: 1.1920 - val_accuracy: 0.4686 - val_loss: 1.2831\n","Epoch 62/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 81ms/step - accuracy: 0.5096 - loss: 1.2084 - val_accuracy: 0.4151 - val_loss: 1.2948\n","Epoch 63/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 110ms/step - accuracy: 0.4725 - loss: 1.2253 - val_accuracy: 0.4906 - val_loss: 1.2229\n","Epoch 64/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 78ms/step - accuracy: 0.5259 - loss: 1.1791 - val_accuracy: 0.4874 - val_loss: 1.2304\n","Epoch 65/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 80ms/step - accuracy: 0.5217 - loss: 1.1437 - val_accuracy: 0.5094 - val_loss: 1.2646\n","Epoch 66/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 128ms/step - accuracy: 0.5264 - loss: 1.1375 - val_accuracy: 0.4874 - val_loss: 1.2353\n","Epoch 67/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 97ms/step - accuracy: 0.5459 - loss: 1.1177 - val_accuracy: 0.4717 - val_loss: 1.3847\n","Epoch 68/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - accuracy: 0.5189 - loss: 1.1550 - val_accuracy: 0.4843 - val_loss: 1.2612\n","Epoch 69/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 78ms/step - accuracy: 0.5448 - loss: 1.1476 - val_accuracy: 0.4937 - val_loss: 1.2566\n","Epoch 70/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - accuracy: 0.5403 - loss: 1.1253 - val_accuracy: 0.5094 - val_loss: 1.1684\n","Epoch 71/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 112ms/step - accuracy: 0.5444 - loss: 1.1044 - val_accuracy: 0.4497 - val_loss: 1.3955\n","Epoch 72/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 80ms/step - accuracy: 0.5655 - loss: 1.1050 - val_accuracy: 0.5409 - val_loss: 1.1591\n","Epoch 73/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 76ms/step - accuracy: 0.5641 - loss: 1.0761 - val_accuracy: 0.5283 - val_loss: 1.1927\n","Epoch 74/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 104ms/step - accuracy: 0.5665 - loss: 1.0630 - val_accuracy: 0.5063 - val_loss: 1.2140\n","Epoch 75/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - accuracy: 0.5491 - loss: 1.1342 - val_accuracy: 0.5000 - val_loss: 1.1903\n","Epoch 76/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - accuracy: 0.5971 - loss: 1.0484 - val_accuracy: 0.4937 - val_loss: 1.2722\n","Epoch 77/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 94ms/step - accuracy: 0.5410 - loss: 1.1215 - val_accuracy: 0.5094 - val_loss: 1.1999\n","Epoch 78/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 79ms/step - accuracy: 0.5386 - loss: 1.1465 - val_accuracy: 0.5535 - val_loss: 1.1520\n","Epoch 79/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 78ms/step - accuracy: 0.5214 - loss: 1.1436 - val_accuracy: 0.5189 - val_loss: 1.1889\n","Epoch 80/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 94ms/step - accuracy: 0.5566 - loss: 1.1477 - val_accuracy: 0.4969 - val_loss: 1.2298\n","Epoch 81/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 80ms/step - accuracy: 0.5701 - loss: 1.0802 - val_accuracy: 0.5252 - val_loss: 1.2124\n","Epoch 82/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 78ms/step - accuracy: 0.5630 - loss: 1.0670 - val_accuracy: 0.4937 - val_loss: 1.2909\n","Epoch 83/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 94ms/step - accuracy: 0.5560 - loss: 1.1275 - val_accuracy: 0.5094 - val_loss: 1.1756\n","Epoch 84/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 98ms/step - accuracy: 0.5512 - loss: 1.0561 - val_accuracy: 0.5031 - val_loss: 1.2500\n","Epoch 85/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 78ms/step - accuracy: 0.5778 - loss: 1.0949 - val_accuracy: 0.5126 - val_loss: 1.2403\n","Epoch 86/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - accuracy: 0.5765 - loss: 1.1059 - val_accuracy: 0.5409 - val_loss: 1.1147\n","Epoch 87/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 122ms/step - accuracy: 0.5291 - loss: 1.1117 - val_accuracy: 0.5157 - val_loss: 1.1774\n","Epoch 88/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 80ms/step - accuracy: 0.5726 - loss: 1.0346 - val_accuracy: 0.5314 - val_loss: 1.2070\n","Epoch 89/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 81ms/step - accuracy: 0.5971 - loss: 1.0842 - val_accuracy: 0.5252 - val_loss: 1.1654\n","Epoch 90/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 104ms/step - accuracy: 0.5805 - loss: 1.0400 - val_accuracy: 0.5535 - val_loss: 1.1458\n","Epoch 91/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 77ms/step - accuracy: 0.5909 - loss: 1.0693 - val_accuracy: 0.5692 - val_loss: 1.0984\n","Epoch 92/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 97ms/step - accuracy: 0.6004 - loss: 1.0325 - val_accuracy: 0.5755 - val_loss: 1.1041\n","Epoch 93/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 97ms/step - accuracy: 0.6160 - loss: 1.0127 - val_accuracy: 0.5377 - val_loss: 1.1268\n","Epoch 94/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 78ms/step - accuracy: 0.6037 - loss: 0.9714 - val_accuracy: 0.5629 - val_loss: 1.1379\n","Epoch 95/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - accuracy: 0.5658 - loss: 1.0489 - val_accuracy: 0.4874 - val_loss: 1.2680\n","Epoch 96/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 89ms/step - accuracy: 0.5696 - loss: 1.0516 - val_accuracy: 0.5314 - val_loss: 1.1741\n","Epoch 97/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - accuracy: 0.5812 - loss: 1.0187 - val_accuracy: 0.5535 - val_loss: 1.1405\n","Epoch 98/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 87ms/step - accuracy: 0.6305 - loss: 0.9461 - val_accuracy: 0.5629 - val_loss: 1.0861\n","Epoch 99/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 101ms/step - accuracy: 0.6097 - loss: 0.9571 - val_accuracy: 0.5157 - val_loss: 1.0940\n","Epoch 100/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 78ms/step - accuracy: 0.6184 - loss: 0.9674 - val_accuracy: 0.5283 - val_loss: 1.1234\n"]}],"source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout\n","from tensorflow.keras.callbacks import EarlyStopping\n","\n","early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n","# Define the model\n","model = Sequential()\n","\n","# First convolution layer\n","model.add(Conv2D(32, (3, 3), input_shape=(150, 150, 1)))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","# Second convolution layer\n","model.add(Conv2D(64, (3, 3)))  # Increased the number of filters to 64\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","# Third convolution layer\n","model.add(Conv2D(128, (3, 3)))  # Further increased to 128 filters\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","# Fourth convolution layer (Newly added)\n","model.add(Conv2D(256, (3, 3)))  # Adding more filters to capture deeper features\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","# Fifth convolution layer (Newly added)\n","model.add(Conv2D(256, (3, 3)))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","# Flatten the output\n","model.add(Flatten())\n","\n","# Fully connected layer 1\n","model.add(Dense(256))  # Increased the number of units for more complexity\n","model.add(Activation('relu'))\n","\n","# Dropout to prevent overfitting\n","model.add(Dropout(0.5))  # Increased dropout rate slightly to prevent overfitting with deeper layers\n","\n","# Fully connected layer 2\n","model.add(Dense(128))\n","model.add(Activation('relu'))\n","\n","# Dropout to prevent overfitting\n","model.add(Dropout(0.5))\n","\n","# Fully connected layer 3\n","model.add(Dense(64))\n","model.add(Activation('relu'))\n","\n","# Dropout to prevent overfitting\n","model.add(Dropout(0.5))\n","\n","# Output layer for multiclass classification\n","model.add(Dense(5))  # 5 output units for 5 classes\n","model.add(Activation('softmax'))\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","\n","# Train the model\n","history = model.fit(train_generator, epochs=100, validation_data=validation_generator, callbacks=[early_stopping])\n","\n","\n"]},{"cell_type":"code","execution_count":49,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":568,"status":"ok","timestamp":1729242938448,"user":{"displayName":"Muhammad El Wazir","userId":"00752065405578931370"},"user_tz":-180},"id":"-pC9qpvpth_X","outputId":"7065fca2-a44d-4a06-c76f-a2f90f567318"},"outputs":[{"output_type":"stream","name":"stdout","text":["Final training accuracy: 0.6180391907691956\n","Final validation accuracy: 0.5283018946647644\n"]}],"source":["# Print final training and validation accuracy after training\n","train_acc = history.history['accuracy'][-1]\n","val_acc = history.history['val_accuracy'][-1]\n","\n","print(f\"Final training accuracy: {train_acc}\")\n","print(f\"Final validation accuracy: {val_acc}\")\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"mount_file_id":"1Sbwtc0kRM74ezqi5cOyiAHf2AWsyO2ek","authorship_tag":"ABX9TyO3i4vxWrfJACLVR3wz4zoy"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}